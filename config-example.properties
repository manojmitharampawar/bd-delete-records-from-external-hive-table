# Example Configuration File for Hive Table Deletion Job

# This file demonstrates how to configure the job using a properties file
# Usage: spark-submit ... --config /path/to/this/file.properties

# ============================================
# Spark Configuration
# ============================================

# Partition overwrite mode (dynamic recommended)
spark.sql.sources.partitionOverwriteMode=dynamic

# ORC optimization settings
spark.sql.orc.impl=native
spark.sql.orc.enableVectorizedReader=true
spark.sql.orc.filterPushdown=true
spark.sql.hive.convertMetastoreOrc=true
spark.sql.orc.compression.codec=snappy

# Adaptive query execution
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true

# Hive settings
spark.sql.hive.verifyPartitionPath=true
spark.sql.hive.metastorePartitionPruning=true

# ============================================
# Backup Configuration
# ============================================

# Backup strategy: hive_table or hdfs
backup.strategy=hive_table

# Backup retention in days
backup.retention.days=7

# Backup table suffix (for hive_table strategy)
backup.table.suffix=_backup

# Backup location (for hdfs strategy)
# backup.location=/backup/my_database/my_table

# ============================================
# Validation Configuration
# ============================================

# Enable post-deletion validation
validation.enabled=true

# Number of records to sample for integrity validation
validation.sample.size=10000

# Tolerance percentage for record count validation
# 0.0 = exact match required
# 0.1 = allow 0.1% variance
validation.tolerance.percent=0.0

# ============================================
# Recovery Configuration
# ============================================

# Enable automatic recovery on failure
recovery.auto.enabled=true

# Maximum number of recovery retry attempts
recovery.max.retries=3

# ============================================
# Performance Configuration
# ============================================

# Number of partitions to process in parallel
partition.parallelism=10

# Batch size for processing records
batch.size=1000000

# ============================================
# Execution Mode
# ============================================

# Dry run mode (preview deletions without executing)
dry.run.enabled=false
