# Hive Table Deletion Job - Default Configuration

# Spark Configuration
spark.app.name=HiveTableDeletionJob
spark.sql.sources.partitionOverwriteMode=dynamic
spark.sql.orc.impl=native
spark.sql.orc.enableVectorizedReader=true
spark.sql.orc.filterPushdown=true
spark.sql.hive.convertMetastoreOrc=true
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true

# Backup Configuration
backup.strategy=hive_table
backup.retention.days=7
backup.table.suffix=_backup

# Validation Configuration
validation.enabled=true
validation.sample.size=10000
validation.tolerance.percent=0.0

# Recovery Configuration
recovery.auto.enabled=true
recovery.max.retries=3

# Performance Configuration
partition.parallelism=10
batch.size=1000000

# Dry Run Mode
dry.run.enabled=false
